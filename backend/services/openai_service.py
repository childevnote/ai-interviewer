
from openai import OpenAI
from PyPDF2 import PdfReader
from dotenv import load_dotenv
import io
import os
import base64
import json
from fastapi import UploadFile, File, HTTPException
import traceback
from schemas.request import ChatRequest, SimulationRequest, EvaluationRequest, HintRequest

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    print("ğŸš¨ ê²½ê³ : OPENAI_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

client = OpenAI(api_key=api_key)


async def upload_resume_analysis(file: UploadFile):
    """ì´ë ¥ì„œ PDFë¥¼ ì½ê³  GPTë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        content = await file.read()
        pdf_reader = PdfReader(io.BytesIO(content))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        if len(text.strip()) < 50:
            return {
                "text": "", 
                "reliability": {"score": 0, "reason": "ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ë¶€ì¡±í•˜ì—¬ íŒë…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            }

        check_prompt = """
        ë‹¹ì‹ ì€ ì±„ìš© ë‹´ë‹¹ìì…ë‹ˆë‹¤. 
        ì œê³µëœ í…ìŠ¤íŠ¸ê°€ 'ì±„ìš© ì´ë ¥ì„œ'ë¡œì„œ ì í•©í•œ í˜•ì‹ì„ ê°–ì¶”ê³  ìˆëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
        [ì¶œë ¥ í¬ë§· - JSON]
        {
            "score": 0~100 ì‚¬ì´ì˜ ì •ìˆ˜,
            "reason": "í•œ ì¤„ ìš”ì•½"
        }
        """

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": check_prompt},
                {"role": "user", "content": text[:3000]}
            ],
            response_format={"type": "json_object"}
        )
        
        analysis_result = json.loads(completion.choices[0].message.content)

        return {
            "text": text,
            "reliability": analysis_result 
        }

    except Exception as e:
        print(f"ğŸš¨ Upload Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def generate_chat_response(request: ChatRequest):
    """GPTì™€ ì±„íŒ…í•˜ê³  ì‘ë‹µì„ TTSë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        messages = request.history.copy()
        current_q_count = sum(1 for m in messages if m['role'] == 'assistant')
        if current_q_count >= request.question_count:
            closing_text = "ëª¨ë“  ì§ˆë¬¸ì´ ëë‚¬ìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤."
            speech_response = client.audio.speech.create(
                model="tts-1", voice="onyx", input=closing_text
            )
            audio_b64 = base64.b64encode(speech_response.content).decode('utf-8')

            return {
                "ai_message": closing_text,
                "audio_data": audio_b64,
                "is_finished": True 
            }

        remaining_count = request.question_count - current_q_count
        role_instruction = f"ë‹¹ì‹ ì€ {request.role} ì§ë¬´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤." if request.role else "ë‹¹ì‹ ì€ ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤."
        system_content = f"""
        [ì¤‘ìš” ì§€ì¹¨ - ë©´ì ‘ê´€ ëª¨ë“œ]
        ì—­í• : {role_instruction}
        ëª©í‘œ: ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ ê²€í† í•˜ê³  {request.role} ì§ë¬´ ì—­ëŸ‰ì„ ê²€ì¦í•˜ëŠ” ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤.
        í–‰ë™: ì§ˆë¬¸ë§Œ í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ í‰ê°€í•˜ê±°ë‚˜ ì¹­ì°¬("ì¢‹ìŠµë‹ˆë‹¤" ë“±)í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

        [ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì •ë³´]
        - ì´ ëª©í‘œ ì§ˆë¬¸ ìˆ˜: {request.question_count}ê°œ
        - í˜„ì¬ ì§„í–‰ëœ ì§ˆë¬¸ ìˆ˜: {current_q_count}ê°œ
        - ì´ë²ˆì´ {current_q_count + 1}ë²ˆì§¸ ì§ˆë¬¸ì…ë‹ˆë‹¤.
        - ì•ìœ¼ë¡œ ë‚¨ì€ ì§ˆë¬¸ì€ {remaining_count - 1}ê°œì…ë‹ˆë‹¤.

        í–‰ë™ ì›ì¹™:
	        1.	ëŒ€ë‹µì„ í•˜ì§€ ì•ŠëŠ”ë‹¤.
            â†’ ë‹¹ì‹ ì€ ì§ˆë¬¸ë§Œ í•œë‹¤. ì§€ì›ìê°€ ë‹µí•œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ì„ ë§Œë“ ë‹¤.
            2.	ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ì§ë¬´ ì¤‘ì‹¬ì´ë©°, ë‚œì´ë„ëŠ” ì§€ì›ìì˜ ë‹µë³€ ìˆ˜ì¤€ì— ë§ì¶° ì ì§„ì ìœ¼ë¡œ ë†’ì¸ë‹¤.
            3.	ëª¨í˜¸í•œ ë‹µë³€ì„ ë°›ìœ¼ë©´
            â†’ â€œì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?â€
            ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëª…í™•ì„±ì„ ìš”êµ¬í•œë‹¤.
            4.	ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬:
            â€¢	ê¸°ìˆ  ì—­ëŸ‰ ê´€ë ¨ ì§ˆë¬¸
            â€¢	í”„ë¡œì íŠ¸ ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸
            â€¢	ë¬¸ì œ í•´ê²° ëŠ¥ë ¥/ë…¼ë¦¬ì  ì‚¬ê³  ì§ˆë¬¸
            â€¢	í˜‘ì—… ê²½í—˜/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ ì§ˆë¬¸
            â€¢	ìƒí™© ê¸°ë°˜ ì§ˆë¬¸ (Behavioral Questions)
            â€¢	ì„±í–¥/ë¬¸í™” ì í•©ì„±(Fit) ì§ˆë¬¸
            5.	í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•œë‹¤.
            â†’ ì§€ì›ìì˜ ë‹µë³€ì´ ì˜¤ê¸° ì „ê¹Œì§€ ë‹¤ë¥¸ ë§ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤.
         	6.	ë„ˆë¬´ ê¸¸ê±°ë‚˜ ê³¼ë„í•˜ê²Œ ì„¤ëª…í•˜ì§€ ì•ŠëŠ”ë‹¤.ì§ˆë¬¸ì€ ê°„ê²°í•˜ê³  ë©´ì ‘ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•œë‹¤.
            7.	ì¹œì ˆí•˜ì§€ë„ ë¶ˆì¹œì ˆí•˜ì§€ë„ ì•Šì€ ì¤‘ë¦½ì ì¸ ë©´ì ‘ê´€ í†¤ì„ ìœ ì§€í•œë‹¤.
            8.	ì§€ì›ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ë¬¸ì¥ì„ ë©´ì ‘ ì¤‘ì—ëŠ” ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
            9. ì–¸ì–´: ë¬´ì¡°ê±´ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. (ìš©ì–´ë‚˜ ê°œë… ë“±ì€ ì˜ì–´ ì‚¬ìš© ê°€ëŠ¥)
            (ì˜ˆ: â€œì¢‹ìŠµë‹ˆë‹¤â€, â€œí›Œë¥­í•´ìš”â€, â€œì˜ëª»ëì–´ìš”â€ ë“± ê¸ˆì§€)
        [í•„ìˆ˜ ì¶œë ¥ í¬ë§· - JSON]
        ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
        {{
            "response": "ì§ˆë¬¸ ë‚´ìš©",
            "is_finished": false
        }}
         'is_finished' = true ì¡°ê±´:
            - ì§€ì›ìê°€ ëª…í™•íˆ ì¢…ë£Œ ì˜ì‚¬ë¥¼ ë°í˜ ("ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤" ë“±).
            - ë‹¹ì‹ ì´ "ë©´ì ‘ì„ ì´ë§Œ ë§ˆì¹©ë‹ˆë‹¤"ë¼ê³  ë§í–ˆì„ ë•Œ.
            ë§íˆ¬ëŠ” ì •ì¤‘í•˜ì§€ë§Œ ì°¨ê°‘ê³  ê±´ì¡°í•œ ì‚¬ë¬´ì ì¸ í†¤(í•˜ì‹­ì‹œì˜¤ì²´/í•´ìš”ì²´)ì„ ìœ ì§€í•˜ì„¸ìš”.
        """

        if messages and messages[0]['role'] == 'system':
            original_resume = messages[0]['content']
            messages[0] = {"role": "system", "content": f"{system_content}\n\n[ì´ë ¥ì„œ]\n{original_resume}"}
        else:
            messages.insert(0, {"role": "system", "content": system_content})

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            response_format={"type": "json_object"}
        )
        
        gpt_raw = completion.choices[0].message.content
        
        try:
            gpt_result = json.loads(gpt_raw)
        except json.JSONDecodeError:
            gpt_result = {"response": "ì£„ì†¡í•©ë‹ˆë‹¤. í†µì‹  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.", "is_finished": False}

        ai_text = gpt_result.get("response", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        is_finished = gpt_result.get("is_finished", False)

        speech_response = client.audio.speech.create(
            model="tts-1",
            voice="onyx",
            input=ai_text
        )
        audio_b64 = base64.b64encode(speech_response.content).decode('utf-8')
        
        return {
            "ai_message": ai_text, 
            "audio_data": audio_b64, 
            "is_finished": is_finished
        }
        
    except Exception as e:
        error_details = traceback.format_exc()
        print(f"ğŸš¨ [CRITICAL ERROR] in generate_chat_response:\n{error_details}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")
    
async def generate_answer_hint(request: HintRequest):
    """í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ëª¨ë²” ë‹µì•ˆ íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        system_prompt = f"""
        ë‹¹ì‹ ì€ {request.role} ì§ë¬´ì˜ ë² í…Œë‘ ë©˜í† ì…ë‹ˆë‹¤.
        ì§€ì›ìì˜ ì´ë ¥ì„œ: {request.resume_text}
        
        ë©´ì ‘ê´€ì˜ ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´, ì§€ì›ìê°€ ë‹µë³€í•  ìˆ˜ ìˆëŠ” 'í•µì‹¬ í‚¤ì›Œë“œ'ì™€ 'ëª¨ë²” ë‹µë³€ ê°€ì´ë“œ'ë¥¼ ì§§ê²Œ ì œì‹œí•˜ì„¸ìš”.
        ë‹µë³€ì„ ëŒ€ì‹  ì¨ì£¼ì§€ ë§ê³ , ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ë§í•´ì•¼ í• ì§€ ê°€ì´ë“œë¼ì¸ì„ 3ì¤„ ì´ë‚´ë¡œ ì œê³µí•˜ì„¸ìš”.
        (ë§íˆ¬: "~í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤." í˜¹ì€ "~í•œ ê²½í—˜ì„ ê°•ì¡°í•˜ì„¸ìš”.")
        """

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë©´ì ‘ê´€ ì§ˆë¬¸: {request.question}"}
            ]
        )
        
        return {"hint": completion.choices[0].message.content}
    except Exception as e:
        print(f"Hint Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def simulate_candidate_answer(request: SimulationRequest):
    """AI ì§€ì›ìì˜ ë‹µë³€ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤."""
    try:
        last_question = request.history[-1]['content']
        candidate_system_prompt = f"""
        ë‹¹ì‹ ì€ ë©´ì ‘ ì§€ì›ìì…ë‹ˆë‹¤. ì´ë ¥ì„œ ë‚´ìš©: {request.resume_text}
        ì§ˆë¬¸: {last_question}
        í•œêµ­ì–´ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": candidate_system_prompt}]
        )
        return {"answer": response.choices[0].message.content}
    except Exception as e:
        print(f"Simulation Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def speech_to_text(file: UploadFile):
    """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (STT)."""
    try:
        content = await file.read()
        audio_file = io.BytesIO(content)
        audio_file.name = "audio.mp3" 
        
        transcript = client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file,
            language="ko" 
        )
        return {"text": transcript.text}
    except Exception as e:
        print(f"STT Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def evaluate_interview_content(request: EvaluationRequest):
    """ë©´ì ‘ ëŒ€í™” ë‚´ìš©ì„ GPTë¡œ í‰ê°€í•©ë‹ˆë‹¤."""
    try:
        evaluation_system_prompt = """
        ë©´ì ‘ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
        ì ìˆ˜ëŠ” **100ì  ë§Œì **ì„ ê¸°ì¤€ìœ¼ë¡œ ì¸¡ì •í•´ì•¼ í•©ë‹ˆë‹¤.

        ì¶œë ¥ í˜•ì‹ (JSON):
        { 
          "score": ì ìˆ˜, 
          "feedback": "ë‚´ìš©", 
          "summary": "ìš”ì•½" 
        }
        """
        
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": evaluation_system_prompt},
                {"role": "user", "content": json.dumps(request.history, ensure_ascii=False)}
            ],
            response_format={"type": "json_object"}
        )
        
        eval_result = json.loads(completion.choices[0].message.content)
        return eval_result
    except Exception as e:
        print(f"Eval Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))