import { useState, useRef, useEffect, ChangeEvent } from "react";
import axios from "axios";
import "./App.css";

interface Message {
  role: "system" | "user" | "assistant";
  content: string;
}

type Turn = "idle" | "ai" | "user" | "processing";

function App() {
  const [resumeText, setResumeText] = useState<string>("");
  const [messages, setMessages] = useState<Message[]>([]);
  const [isInterviewing, setIsInterviewing] = useState<boolean>(false);
  const [turn, setTurn] = useState<Turn>("idle");
  const [timeLeft, setTimeLeft] = useState<number>(300);
  const [isTestMode, setIsTestMode] = useState<boolean>(false);

  // ìë§‰ & ì¢…ë£Œ ìƒíƒœ
  const [captionText, setCaptionText] = useState<string>("");
  const [captionSpeaker, setCaptionSpeaker] = useState<"ai" | "user" | null>(
    null
  );
  const [isFinishing, setIsFinishing] = useState<boolean>(false);

  // Refs
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const silenceStartRef = useRef<number | null>(null);
  const requestRef = useRef<number | null>(null);
  const volumeBarRef = useRef<HTMLDivElement | null>(null);

  const SILENCE_THRESHOLD = 15;
  const SILENCE_DURATION = 3000;

  // íƒ€ì´ë¨¸
  useEffect(() => {
    let interval: number | undefined;
    if (isInterviewing && timeLeft > 0) {
      interval = setInterval(() => setTimeLeft((t) => t - 1), 1000);
    } else if (timeLeft === 0) {
      alert("ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
      stopAll();
    }
    return () => clearInterval(interval);
  }, [isInterviewing, timeLeft]);

  // í…ŒìŠ¤íŠ¸ ëª¨ë“œ ìë™ ë‹µë³€ íŠ¸ë¦¬ê±°
  useEffect(() => {
    if (isInterviewing && turn === "user" && isTestMode) {
      simulateUserResponse();
    }
  }, [turn, isInterviewing, isTestMode]);

  const stopAll = () => {
    setIsInterviewing(false);
    setCaptionText("");
    if (audioContextRef.current && audioContextRef.current.state !== "closed") {
      audioContextRef.current.close();
    }
    if (requestRef.current) cancelAnimationFrame(requestRef.current);
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      mediaRecorderRef.current.stop();
    }
  };

  const handleFileUpload = async (e: ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;
    const formData = new FormData();
    formData.append("file", file);

    try {
      const res = await axios.post("http://localhost:8000/upload", formData);
      setResumeText(res.data.text);
    } catch (err) {
      console.error(err);
      alert("íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨");
    }
  };

  const startInterview = async () => {
    if (!resumeText) return alert("ì´ë ¥ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.");
    setIsInterviewing(true);
    setTurn("ai");

    const initialHistory: Message[] = [
      {
        role: "system",
        content: `ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ë ¥ì„œë¥¼ ë³´ê³  ë©´ì ‘ì„ ì§„í–‰í•˜ì„¸ìš”: ${resumeText}`,
      },
      { role: "user", content: "ë©´ì ‘ì„ ì‹œì‘í•´ì¤˜. ì²« ì¸ì‚¬ë¥¼ í•´ì¤˜." },
    ];
    setMessages(initialHistory);
    await fetchAiResponse(initialHistory);
  };

  const fetchAiResponse = async (history: Message[]) => {
    setTurn("ai");
    setCaptionSpeaker("ai");
    setCaptionText("ì§ˆë¬¸ ìƒì„± ì¤‘...");

    try {
      const res = await axios.post("http://localhost:8000/chat", {
        message: "",
        history: history,
      });
      const { ai_message, audio_data, is_finished } = res.data;

      setMessages((prev) => [
        ...prev,
        { role: "assistant", content: ai_message },
      ]);
      setCaptionText(ai_message);

      if (is_finished) setIsFinishing(true);

      playAudio(audio_data);
    } catch (err) {
      console.error(err);
      setTurn("idle");
      setCaptionText("");
    }
  };

  const playAudio = (base64Audio: string) => {
    if (audioRef.current) {
      audioRef.current.src = `data:audio/mp3;base64,${base64Audio}`;
      audioRef.current.play().catch((e) => console.error("ì¬ìƒ ì˜¤ë¥˜:", e));
    }
  };

  const handleAudioEnded = () => {
    if (captionSpeaker === "ai") setCaptionText("");

    if (isFinishing) {
      alert("ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!");
      stopAll();
      setIsFinishing(false);
      return;
    }

    if (isInterviewing) {
      if (!isTestMode) startRecording();
      else setTurn("user");
    }
  };

  // AI ì§€ì›ì ì‹œë®¬ë ˆì´ì…˜
  const simulateUserResponse = async () => {
    setCaptionSpeaker("user");
    setCaptionText("ìƒê° ì¤‘...");

    await new Promise((r) => setTimeout(r, 1500));

    try {
      const res = await axios.post("http://localhost:8000/simulate", {
        history: messages,
        resume_text: resumeText,
      });

      const simulatedAnswer = res.data.answer;
      setCaptionText(simulatedAnswer);

      const newMessages: Message[] = [
        ...messages,
        { role: "user", content: simulatedAnswer },
      ];
      setMessages(newMessages);

      await new Promise((r) => setTimeout(r, 2000));
      await fetchAiResponse(newMessages);
    } catch (err) {
      console.error("Simulation Error:", err);
      setTurn("idle");
    }
  };

  const startRecording = async () => {
    setTurn("user");
    setCaptionSpeaker("user");
    setCaptionText("ë“£ê³  ìˆìŠµë‹ˆë‹¤..."); // ë“£ëŠ” ì¤‘ ìƒíƒœ í‘œì‹œ

    try {
      if (
        audioContextRef.current &&
        audioContextRef.current.state !== "closed"
      ) {
        await audioContextRef.current.close();
      }
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, {
          type: "audio/mp3",
        });
        await sendAudioToBackend(audioBlob);

        if (requestRef.current) cancelAnimationFrame(requestRef.current);
        stream.getTracks().forEach((track) => track.stop());
        if (volumeBarRef.current) volumeBarRef.current.style.width = "0%";
      };

      mediaRecorder.start();
      detectSilence(stream, mediaRecorder);
    } catch (err) {
      console.error("ë§ˆì´í¬ ì˜¤ë¥˜:", err);
      setTurn("idle");
    }
  };

  const detectSilence = (stream: MediaStream, mediaRecorder: MediaRecorder) => {
    const audioContext = new AudioContext();
    audioContextRef.current = audioContext;
    const analyser = audioContext.createAnalyser();
    sourceRef.current = audioContext.createMediaStreamSource(stream);

    sourceRef.current.connect(analyser);
    analyser.fftSize = 512;

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    silenceStartRef.current = null;

    const checkVolume = () => {
      if (!isInterviewing || isTestMode) return;

      analyser.getByteFrequencyData(dataArray);
      let sum = 0;
      for (let i = 5; i < bufferLength; i++) sum += dataArray[i];
      const averageVolume = sum / (bufferLength - 5);

      if (volumeBarRef.current) {
        const visualVol = Math.min(100, averageVolume * 3); // ë¯¼ê°ë„ ì¦ê°€
        volumeBarRef.current.style.width = `${visualVol}%`;
        volumeBarRef.current.style.backgroundColor =
          averageVolume < SILENCE_THRESHOLD ? "#d1d6db" : "#3182f6"; // í† ìŠ¤ ì»¬ëŸ¬ ì ìš©
      }

      if (averageVolume < SILENCE_THRESHOLD) {
        if (silenceStartRef.current === null) {
          silenceStartRef.current = Date.now();
        } else {
          const silenceDuration = Date.now() - silenceStartRef.current;
          if (silenceDuration > SILENCE_DURATION) {
            if (mediaRecorder.state === "recording") {
              mediaRecorder.stop();
              return;
            }
          }
        }
      } else {
        silenceStartRef.current = null;
      }

      requestRef.current = requestAnimationFrame(checkVolume);
    };

    checkVolume();
  };

  const sendAudioToBackend = async (audioBlob: Blob) => {
    setTurn("processing");
    setCaptionText("ë‹µë³€ ì „ì†¡ ì¤‘...");

    const formData = new FormData();
    formData.append("file", audioBlob);

    try {
      const sttRes = await axios.post("http://localhost:8000/stt", formData);
      const userText = sttRes.data.text;

      if (userText.trim()) {
        setCaptionText(userText);
        const newMessages: Message[] = [
          ...messages,
          { role: "user", content: userText },
        ];
        setMessages(newMessages);
        await fetchAiResponse(newMessages);
      } else {
        startRecording();
      }
    } catch (err) {
      console.error("STT ì˜¤ë¥˜:", err);
      setTurn("idle");
      startRecording();
    }
  };

  const formatTime = (seconds: number) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}:${s < 10 ? "0" : ""}${s}`;
  };

  return (
    <div className="app-container">
      <header>
        <h1>AI ëª¨ì˜ ë©´ì ‘</h1>
        <div className="timer">{formatTime(timeLeft)}</div>
      </header>

      {!isInterviewing ? (
        <div className="setup-box">
          <div className="upload-area">
            <label className="file-label">
              <span style={{ fontSize: "24px", marginBottom: "8px" }}>ğŸ“„</span>
              <span>ì´ë ¥ì„œ PDF ì—…ë¡œë“œ</span>
              <input
                type="file"
                accept=".pdf"
                onChange={handleFileUpload}
                hidden
              />
            </label>
            {resumeText && (
              <div className="file-status">âœ… ì´ë ¥ì„œ ë¶„ì„ ì™„ë£Œ</div>
            )}
          </div>

          <div className="test-mode-card">
            <input
              type="checkbox"
              checked={isTestMode}
              onChange={(e) => setIsTestMode(e.target.checked)}
            />
            <span>ìë™ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì¼œê¸°</span>
          </div>

          <button
            className="primary-btn"
            onClick={startInterview}
            disabled={!resumeText}
          >
            ë©´ì ‘ ì‹œì‘í•˜ê¸°
          </button>
        </div>
      ) : (
        <div className="interview-room">
          <div className="status-message">
            {turn === "ai" && (
              <>
                <span style={{ color: "#ff4b4b" }}>â—</span> ë©´ì ‘ê´€ ì§ˆë¬¸ ì¤‘
              </>
            )}
            {turn === "user" && !isTestMode && (
              <>
                <span style={{ color: "#3182f6" }}>â—</span> ë‹µë³€ì„ ë§ì”€í•´ì£¼ì„¸ìš”
              </>
            )}
            {turn === "user" && isTestMode && (
              <>
                <span style={{ color: "#3182f6" }}>â—</span> AI ì§€ì›ì ë‹µë³€ ìƒì„±
                ì¤‘
              </>
            )}
            {turn === "processing" && (
              <span style={{ color: "#8b95a1" }}>Thinking...</span>
            )}
          </div>

          <div className="avatars">
            <div
              className={`avatar-wrapper ai ${turn === "ai" ? "active" : ""}`}
            >
              <div className="avatar">ğŸ¤–</div>
              <span className="avatar-name">ë©´ì ‘ê´€</span>
            </div>
            <div
              className={`avatar-wrapper user ${
                turn === "user" ? "active" : ""
              }`}
            >
              <div className="avatar">{isTestMode ? "ğŸ§ª" : "ğŸ§‘"}</div>
              <span className="avatar-name">
                {isTestMode ? "AI ì§€ì›ì" : "ë‚˜"}
              </span>
            </div>
          </div>

          {/* ë³¼ë¥¨ ë¯¸í„° (User í„´ì¼ ë•Œë§Œ) */}
          {turn === "user" && !isTestMode && (
            <div className="volume-container">
              <div className="volume-bar-bg">
                <div
                  ref={volumeBarRef}
                  className="volume-bar-fill"
                  style={{ width: "0%" }}
                ></div>
              </div>
            </div>
          )}

          <div className="controls">
            <button
              className="secondary-btn"
              onClick={() => {
                stopAll();
                alert("ë©´ì ‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.");
              }}
            >
              ë©´ì ‘ ì¢…ë£Œí•˜ê¸°
            </button>
          </div>

          <audio ref={audioRef} onEnded={handleAudioEnded} hidden />

          {/* í•˜ë‹¨ ìë§‰ ì˜¤ë²„ë ˆì´ */}
          {captionText && (
            <div className="caption-overlay">
              <strong>
                {captionSpeaker === "ai"
                  ? "ë©´ì ‘ê´€"
                  : isTestMode
                  ? "AI ì§€ì›ì"
                  : "ë‚˜"}
              </strong>
              {captionText}
            </div>
          )}
        </div>
      )}
    </div>
  );
}

export default App;
