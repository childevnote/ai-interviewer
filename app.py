import streamlit as st
import os
from openai import OpenAI
from PyPDF2 import PdfReader
from streamlit_mic_recorder import mic_recorder
from dotenv import load_dotenv
import base64

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if not api_key:
    st.error("âš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=api_key)

st.set_page_config(page_title="AI ì‹¤ì „ ë©´ì ‘", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ AI ì‹¤ì „ ëª¨ì˜ë©´ì ‘ (Powered by OpenAI)")

# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "interview_started" not in st.session_state:
    st.session_state.interview_started = False

# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def get_pdf_text(pdf_docs):
    text = ""
    pdf_reader = PdfReader(pdf_docs)
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

# OpenAI TTS (í…ìŠ¤íŠ¸ -> ìŒì„±) ë° ìë™ ì¬ìƒ
def speak_text(text):
    try:
        response = client.audio.speech.create(
            model="tts-1",
            voice="alloy", # ëª©ì†Œë¦¬: alloy, echo, fable, onyx, nova, shimmer
            input=text
        )
        # ë¸Œë¼ìš°ì € ìë™ ì¬ìƒì„ ìœ„í•œ HTML ìƒì„±
        audio_base64 = base64.b64encode(response.content).decode('utf-8')
        audio_tag = f'<audio autoplay="true" src="data:audio/mp3;base64,{audio_base64}">'
        st.markdown(audio_tag, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"ìŒì„± ì¬ìƒ ì˜¤ë¥˜: {e}")

# === í™”ë©´ êµ¬ì„± ===
with st.sidebar:
    st.header("âš™ï¸ ë©´ì ‘ ì„¤ì •")
    job_role = st.selectbox("ì§€ì› ì§ë¬´", ["ë°±ì—”ë“œ ê°œë°œì", "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "AI ì—”ì§€ë‹ˆì–´", "PM", "ë°ì´í„° ë¶„ì„ê°€", "ë§ˆì¼€í„°"])
    uploaded_file = st.file_uploader("ì´ë ¥ì„œ(PDF) ì—…ë¡œë“œ", type=["pdf"])
    
    start_btn = st.button("ë©´ì ‘ ì‹œì‘í•˜ê¸°")
    
    if start_btn and uploaded_file:
        with st.spinner("ì´ë ¥ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            resume_text = get_pdf_text(uploaded_file)
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë©´ì ‘ê´€ í˜ë¥´ì†Œë‚˜)
            system_prompt = f"""
            ë‹¹ì‹ ì€ {job_role} ì±„ìš© ë©´ì ‘ê´€ì…ë‹ˆë‹¤. 
            ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ë„ ìˆëŠ” ê¸°ìˆ  ë©´ì ‘ ë° ì¸ì„± ë©´ì ‘ì„ ì§„í–‰í•˜ì„¸ìš”.
            
            [ë©´ì ‘ ê°€ì´ë“œë¼ì¸]
            1. í•œ ë²ˆì— 'ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸'ë§Œ í•˜ì„¸ìš”. ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°œ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”.
            2. ì§€ì›ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•˜ë©´, êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ë¬»ëŠ” 'ê¼¬ë¦¬ ì§ˆë¬¸'ì„ ë˜ì§€ì„¸ìš”.
            3. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ê³  í”„ë¡œí˜ì…”ë„í•œ ì¡´ëŒ“ë§("~í•˜ì…¨ë‚˜ìš”?", "~ì¸ê°€ìš”?")ì„ ì‚¬ìš©í•˜ì„¸ìš”.
            4. ë©´ì ‘ ì´ˆë°˜ì—ëŠ” ê¸´ì¥ì„ í’€ì–´ì£¼ëŠ” ê°€ë²¼ìš´ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
            
            [ì§€ì›ì ì´ë ¥ì„œ ë‚´ìš©]
            {resume_text}
            """
            
            # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
            st.session_state.messages = [{"role": "system", "content": system_prompt}]
            
            # ì²« ì¸ì‚¬ë§ ìƒì„± ìš”ì²­
            completion = client.chat.completions.create(
                model="gpt-4o", 
                messages=st.session_state.messages + [{"role": "user", "content": "ë©´ì ‘ì„ ì‹œì‘í•´. ì²« ì¸ì‚¬ì™€ ì²« ì§ˆë¬¸ì„ í•´ì¤˜."}]
            )
            first_greeting = completion.choices[0].message.content
            
            # AI ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": first_greeting})
            st.session_state.interview_started = True
            st.rerun()

# [ë©”ì¸ í™”ë©´]
if st.session_state.interview_started:
    # 1. ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìˆ¨ê¹€)
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"]):
                st.write(msg["content"])

    st.write("---")
    st.write("ğŸ‘‡ **ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€í•˜ì„¸ìš”:**")
    
    # ë§ˆì´í¬ ì…ë ¥ (mic_recorder)
    audio = mic_recorder(
        start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘", 
        stop_prompt="â¹ï¸ ë…¹ìŒ ì™„ë£Œ", 
        key='recorder',
        just_once=False,
        use_container_width=True
    )

    if audio:
        # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ ë¡œì§
        if "last_audio_id" not in st.session_state:
            st.session_state.last_audio_id = None
        
        if st.session_state.last_audio_id != audio['id']:
            st.session_state.last_audio_id = audio['id']
            
            # (1) ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥
            audio_path = "temp_audio.mp3"
            with open(audio_path, "wb") as f:
                f.write(audio['bytes'])
            
            try:
                with st.spinner("ğŸ‘‚ ë“£ëŠ” ì¤‘... (Whisper)"):
                    # (2) STT: OpenAI Whisper
                    with open(audio_path, "rb") as audio_file:
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1", 
                            file=audio_file
                        )
                    user_text = transcript.text
                
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({"role": "user", "content": user_text})
                
                with st.spinner("ğŸ§  ìƒê°í•˜ëŠ” ì¤‘... (GPT-4o)"):
                    # (3) Brain: GPT-4o
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=st.session_state.messages
                    )
                    ai_response = response.choices[0].message.content
                
                # AI ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
                
                # (4) TTS: OpenAI Speech
                speak_text(ai_response)
                
                st.rerun()
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

else:
    # ì´ˆê¸° ì•ˆë‚´ í™”ë©´
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì§ë¬´ë¥¼ ì„ íƒí•˜ê³  ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•œ ë’¤ 'ë©´ì ‘ ì‹œì‘í•˜ê¸°'ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")